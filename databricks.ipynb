{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d188aa16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de49e308",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46bb95d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('/Workspace/Users/nadia.cavoli@outlook.com.ar/datos_ventas_dummy.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88737163",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222b1b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfcordoba = df[df['estado'] == 'Córdoba']\n",
    "dfcordoba\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c53ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfbuenosaires = df[df['estado'] == 'Buenos Aires']\n",
    "dfbuenosaires.display()\n",
    "'dbfs:/FileStore/Facundo/cordoba'\n",
    "'dbfs:/FileStore/Facundo/bsas'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30cb4f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convierte el DataFrame de Pandas 'dfcordoba' a un DataFrame de Spark\n",
    "df_cordoba_spark = spark.createDataFrame(dfcordoba)\n",
    "\n",
    "# Convierte el DataFrame de Pandas 'dfbuenosaires' a un DataFrame de Spark\n",
    "df_buenosaires_spark = spark.createDataFrame(dfbuenosaires)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e563bd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guarda el DataFrame df_cordoba_spark en formato Parquet dentro del directorio FileStore/Gabriela/cordoba\n",
    "df_cordoba_spark.write.format(\"parquet\").save('/FileStore/Gabriela/cordoba')\n",
    "\n",
    "# Guarda el DataFrame df_buenosaires_spark en formato Parquet dentro del directorio FileStore/Gabriela/bsas\n",
    "df_buenosaires_spark.write.format(\"parquet\").save('/FileStore/Gabriela/bsas')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711a58ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comando mágico de Databricks para listar el contenido del directorio FileStore en DBFS\n",
    "# Muestra todos los archivos y carpetas almacenados en dbfs:/FileStore/\n",
    "%fs ls dbfs:/FileStore/\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9c8abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Muestra el contenido del directorio \"dbfs:/FileStore/Gabriela/\" en Databricks File System (DBFS)\n",
    "# Esto es útil para listar los archivos que subiste al FileStore desde tu cuenta de Databricks\n",
    "display(dbutils.fs.ls(\"dbfs:/FileStore/Gabriela/\"))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
